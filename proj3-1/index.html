<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Andrew Shen and Ryan Chan</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://shenandrew.me/cs184-webpages/proj3-1/">https://shenandrew.me/cs184-webpages/proj3-1/</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<h2 align="middle">Overview</h2>
<p>
    In this project, we explore ray tracing, bounding volume hierarchies, and various lighting techniques. We first
    started by implementing ray generation and intersections between rays and primitives. Next, we implemented bounding 
    volume hierarchies, allowing us to check for intersections much more efficiently. After that, we implemented 
    two different light sampling techniques: uniform hemisphere sampling and direct lighting sampling. This part was 
    very interesting because we got to observe the differences between the two in the renderings, on top of gaining a better 
    understanding of how different styles of lighting are achieved. Finally, we implemented global illumination and 
    adaptive sampling. Adaptive sampling allows us to render more efficiently because we can take less samples on pixels that
    converge faster. Overall, this project was a lot longer in comparison to the previous projects, but it was also very
    insightful in terms of learning how ray tracing and lighting work in computer graphics.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
 	Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
	In order to perform ray generation by transforming an (x, y) coordinate in the image space with normalized coordinates into the world space, we begin by finding a way to translate the image space to camera space. We can do this by shifting the origin of the image space to (0, 0) by subtracting (-0.5, -0.5) from each coordinate. Then we need to scale the resulting coordinates so that it matches the dimensions of the image space. We can do this by scaling the x and y coordinates by: 
</p>

<p align="middle"><pre align="middle">(2tan(0.5 * hFov * PI/180.0), 2tan(0.5 * vFov * PI/180.0))</pre></p>
	
<p>
	This gives us the camera space ray which we can convert to world coordinates by multiplying the c2w transformation vector as follows:
</p>

<p align="middle"><pre align="middle">world_ray = c2w * camera_ray</pre></p>

<p>
	The last step is to add in the nClip and fClip as the min_t and max_t values respectively.
</p>

<p>
	Since we want to use Monte Carlo approximation to render the color of the pixel we sample a total of <i>num_samples = ns_aa</i> samples. For each sample, we take a random 2D vector drawn uniformly from a unit square and add it to the origin point to get the vector within the pixel that we wish to sample. Then using the ray generation function from before as well as the <i>est_radiance_global_illumination</i> function, we can compute an average color for the pixel by summing the color of each individual ray and dividng by the total number of samples taken.
</p>

<br>

<h3>
 	Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    For ray-triangle intersections, we implemented the Moller Trumbore algorithm as described in lecture. It is an efficient algorithm for
    calculating the intersection of a ray and triangle because it doesn't need to solve the plane equation for the plane
    containing the triangle. The intersection point calculated by the algorithm is always within the triangle and is therefore correct,
    given valid barycentric coordinates and t-value. The algorithm takes advantage of the fact that barycentric coordinates are invariant, so instead
    of solving for the intersection point in x,y,z coordinates, it solves it in barycentric coordinates, guaranteeing that the intersection point will lie within the triangle if it exists. 

    In our implementation, we first set all the known variables, which are the triangle edges. Next, we solve for the three unknowns: t, b1, and b2.
    We solve for them one at a time, each time checking for validity. For t, we check if it is within the ray's t-range. For b1 and b2,
    we check if they are valid barycentric coordinates, as in they are within 0 and 1 and don't sum to a value greater than 1.
</p>
<br>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/MollerTrumbore.png" align="middle" width="400px"/>
        <figcaption>Moller Trumbore Algorithm</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBempty.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/CBspheres.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
    </tr>
    <!-- <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example3.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example4.dae</figcaption>
      </td>
    </tr> -->
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    Our BVH construction algorithm recusively splits a vector of primitives until that vector of primitives is less than <i>max_leaf_size</i>. For each node in the BVH, we begin by computing the bounding box for all items that are contained within that node and its left and right nodes if it has any. Then, depending on the number of primtives that are contained in this node, we either recurse by splitting the primitives into one of two groups based on our heuristic or turn the node into a leaf node which contains a pointer to the start and end of the list of the primitives. In order to ensure that we do not have infinite recursion in the event that our heuristic splits the primitives into one group with none of the primitives and another group with all of the primitives, we enforce that there must be at least one primitive in each subnode. This ensures that the number of primitives contained in children nodes is strictly less than the parent nodes and so the algorithm will terminate.
</p>

<p>
	Our heuristic algorithm is based on the average centroid of all of the primitives contained within the node and splits based on the either the x, y, or z axis depending on which one has the highest variance. To roughly calculate the variance, we compute the sum of the squared difference from each centroid to the average centroid. Then, we split the primtives into two groups based on whether its centroid is less than or greater than the average centroid in the axis with the greatest sum of squared difference.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/cow.png" align="middle" width="400px"/>
        <figcaption>cow.dae</figcaption>
      </td>
      <td>
        <img src="images/maxplanck.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/teapot.png" align="middle" width="400px"/>
        <figcaption>teapot.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    We compared the effects of the BVH acceleration as outline by the table below. As we can see by the right most column (Speed Up), we can see that BVH accerlation does wonders to improve the total time to render, cutting each render down to less than a second. In addition, the number of rays traced is reduced after using BVH accerlation. There are other statistics as reported by the different commands, but for sake of brevity we decided to omit them to keep only the most revealing statistics. In general, the average number of intersection tests per ray decreases sharply and the number of rays computed per second sharply increases, which makes sense as the two values should be inversely proportional.
</p>

<!-- Example of including multiple figures -->
<div align="middle">
  <table border="1">
    <tr>
      <th>Image</th>
      <th># Primatives</th>
      <th># Rays Traced</th>
      <th>Time to Render (s)</th>
      <th>[BVHAccel] # Rays Traced</th>
      <th>[BVHAccel] Time to Render (s)</th>
      <th>Speed Up (Time to Render / BVHAccel Time to Render)</th>
    </tr>
    <tr>
      <td style="text-align: center">cow.dae</td>
      <td style="text-align: center">5856</td>
      <td style="text-align: center">474844</td>
      <td style="text-align: center">5.89</td>
      <td style="text-align: center">206598</td>
      <td style="text-align: center">0.0644</td>
      <td style="text-align: center">91.46x</td>
    </tr>
    <tr>
      <td style="text-align: center">CBlucy.dae</td>
      <td style="text-align: center">133796</td>
      <td style="text-align: center">363510</td>
      <td style="text-align: center">380.45</td>
      <td style="text-align: center">166431</td>
      <td style="text-align: center">0.0739</td>
      <td style="text-align: center">5148.17x</td>
    </tr>
    <tr>
      <td style="text-align: center">maxplanck.dae</td>
      <td style="text-align: center">50801</td>
      <td style="text-align: center">368148</td>
      <td style="text-align: center">72.72</td>
      <td style="text-align: center">198518</td>
      <td style="text-align: center">0.0679</td>
      <td style="text-align: center">1071.037x</td>
    </tr>
  </table>
</div>
<br>

<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/maxplanck_BVHaccel.png" align="middle" width="400px"/>
        <figcaption>Statistics for generating maxplanck.png with BVH accel</figcaption>
      </td>
      <td>
        <img src="images/maxplanck_no_BVHaccel.png" align="middle" width="400px"/>
        <figcaption>Statistics for generating maxplanck.png without BVH accel</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    In the uniform hemisphere sampling implementation, since we are trying to calculate the amount of light arriving
    in a hemisphere around the hit point, we implement a Monte Carlo estimator to approximate the integral. We have a loop 
    where in each iteration, we take a hemisphere sample.
    Using that sample and the hit point, we cast a ray and check if it 
    intersects any primitives in the BVH. If so, we compute the reflection equation to calculate the amount of outgoing 
    light and add it to a running sum vector. After taking all the samples and repeating the process above, we return the average,
    thus completing the Monte Carlo estimator.

    In the direct sampling implementation, we want to sample all the lights directly, resulting in a less noisy render. 
    For each light in the scene, we sample directions between the light and the hit-point. Like in the uniform hemisphere
    sampling implementation, we cast a ray between the sample and the hit point. If it doesn't intersect with any primitives
    in the BVH, then we know the light illuminates the hit point and we can compute the reflection equation like before. Again,
    we average the running sum with the total number of samples taken and return it.
    
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/dragon_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBdragon.dae rendered with uniform hemisphere sampling</figcaption>
      </td>
      <td>
        <img src="images/dragon_direct.png" align="middle" width="400px"/>
        <figcaption>CBdragon.dae rendered with direct lighting sampling</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/lucy_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae rendered with uniform hemisphere sampling</figcaption>
      </td>
      <td>
        <img src="images/lucy_direct.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae rendered with direct lighting sampling</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_1_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_1_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_1_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_1_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    As we increase the number of light rays, the noise levels in soft shadows decreases. For example, the bunny's shadows
    gradually become less pixelated, smoother, and more diffused as we go from 1 light ray to 64.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    With uniform hemisphere sampling, the resulting renderings are more noisy but also more realistic because it simulates
    indirect lighting better. More specifically, it simulates light bouncing off surfaces in the scene and 
    indirectly illuminating other surfaces. On the other hand, lighting sampling results in less noise and more stylized
    renderings. It simulates direct lighting instead, which produces sharper shadows and highlights throughout the scene.
    Overall, uniform hemisphere sampling produces noisier renderings that have smoother and more diffused lighting, whereas
    lighting sampling produces less noisy renderings with sharper and more directional lighting.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling allows us to eliminate noise in our renderings by using a high number of samples per pixel efficiently.
    Using a fixed number of samples per pixel can be slow and inefficient, especially when we start to increase the number of samples.
    Adaptive sampling solves this problem by taking less samples for pixels that converge faster than others. It achieves this by checking 
    if a pixel is within a certain range with a confidence interval of 95% after some number of samples. If it is, then we
    stop sampling at that pixel.

    In our implementation of adaptive sampling, we kept track of the number of samples taken so far at a pixel and checked
    if it satisfied our condition every samplesPerBatch samples. We also computed the illuminance for each sample and added
    it to s1 and s2, two variables that kept track of the sum of each sample's illuminance and illuminance squared, respectively.
    In our condition that checks if a pixel has converged, we used s1 and s2 to calculate the mean and variance of all samples 
    so far. Then we used the mean, variance, and max tolerance to calculate the final condition. If the condition is satisfied,
    we stop taking samples, and if not, we continue taking samples until the condition is satisfied or until we reach the maximum
    number of samples.
</p>
<br>

<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/s1_s2.png" align="middle" width="400px"/>
        <figcaption>S1 and S2</figcaption>
      </td>
      <td>
        <img src="images/mean_variance.png" align="middle" width="400px"/>
        <figcaption>Mean and variance</figcaption>
      </td>
      <td>
        <img src="images/I_variable.png" align="middle" width="400px"/>
        <figcaption>Variable I</figcaption>
      </td>
      <td>
        <img src="images/convergence_condition.png" align="middle" width="400px"/>
        <figcaption>Convergence condition</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_2048_1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_2048_1_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/walle_2048_1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (wall-e.dae)</figcaption>
      </td>
      <td>
        <img src="images/walle_2048_1_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (wall-e.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
